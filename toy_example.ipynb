{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c422b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   0 | loss=1.2816 | acc=0.50\n",
      "epoch  20 | loss=0.0855 | acc=1.00\n",
      "epoch  40 | loss=0.0409 | acc=1.00\n",
      "epoch  60 | loss=0.0243 | acc=1.00\n",
      "epoch  80 | loss=0.0166 | acc=1.00\n",
      "epoch 100 | loss=0.0124 | acc=1.00\n",
      "epoch 120 | loss=0.0099 | acc=1.00\n",
      "epoch 140 | loss=0.0082 | acc=1.00\n",
      "epoch 160 | loss=0.0069 | acc=1.00\n",
      "epoch 180 | loss=0.0060 | acc=1.00\n",
      "\n",
      "Final predictions:\n",
      "x=[2.0, 3.0], y_true=0, prob=0.004, pred=0\n",
      "x=[1.0, 1.5], y_true=0, prob=0.005, pred=0\n",
      "x=[2.5, 2.2], y_true=0, prob=0.007, pred=0\n",
      "x=[3.0, 0.5], y_true=1, prob=0.993, pred=1\n",
      "x=[4.0, 1.0], y_true=1, prob=0.995, pred=1\n",
      "x=[3.5, 0.2], y_true=1, prob=0.995, pred=1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from Models.MLP.MLPnetwork import MLPNetwork\n",
    "from Models.MLP.Value import Value\n",
    "from Trainer import Trainer\n",
    "data = [\n",
    "    ([2.0, 3.0], 0),\n",
    "    ([1.0, 1.5], 0),\n",
    "    ([2.5, 2.2], 0),\n",
    "    ([3.0, 0.5], 1),\n",
    "    ([4.0, 1.0], 1),\n",
    "    ([3.5, 0.2], 1),\n",
    "]\n",
    "\n",
    "# Binary Cross-Entropy loss for sigmoid outputs\n",
    "def bce_loss(prob, y_true):\n",
    "    \"\"\"\n",
    "    Binary Cross-Entropy Loss for sigmoid outputs.\n",
    "    \n",
    "    prob: Value    # model output after sigmoid (a probability)\n",
    "    y_true: int    # 0 or 1\n",
    "    \"\"\"\n",
    "\n",
    "    # y * log(p)\n",
    "    term1 = prob.log() if y_true == 1 else Value(0.0)\n",
    "\n",
    "    # (1 - y) * log(1 - p)\n",
    "    term2 = (1 - prob).log() if y_true == 0 else Value(0.0)\n",
    "\n",
    "    # BCE = - (term1 + term2)\n",
    "    return -(term1 + term2)\n",
    "    \n",
    "\n",
    "\n",
    "# creating the model with 1 hidden layer and 1 output\n",
    "model = MLPNetwork(\n",
    "    input_dim=2,\n",
    "    n_neurons=[4, 1],          # [hidden_size, output_size]\n",
    "    label=\"toy\",\n",
    "    activation_type=\"tanh\",\n",
    "    classification=\"sigmoid\"\n",
    ")\n",
    "\n",
    "# Training loop (simple SGD)\n",
    "learning_rate = 0.1\n",
    "epochs = 200\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = Value(0.0)\n",
    "    correct = 0\n",
    "\n",
    "    for (x_raw, y_true) in data:\n",
    "        # Forward pass\n",
    "        probs = model.forward(x_raw)\n",
    "        loss = bce_loss(probs[0], y_true)\n",
    "\n",
    "        # Accumulate loss for reporting\n",
    "        total_loss = total_loss + loss\n",
    "\n",
    "        # Accuracy\n",
    "        pred = 1 if probs[0].data > 0.5 else 0\n",
    "        if pred == y_true:\n",
    "            correct += 1\n",
    "\n",
    "        # Backward + update (SGD step)\n",
    "        model.zero_grad()     # reset grads BEFORE backward\n",
    "        loss.backward()\n",
    "        for p in model.parameters():\n",
    "            p.data -= learning_rate * p.grad\n",
    "\n",
    "    # Report average loss + accuracy\n",
    "    if epoch % 20 == 0:\n",
    "        avg_loss = total_loss.data / len(data)\n",
    "        acc = correct / len(data)\n",
    "        print(f\"epoch {epoch:3d} | loss={avg_loss:.4f} | acc={acc:.2f}\")\n",
    "\n",
    "# test\n",
    "print(\"\\nFinal predictions:\")\n",
    "for (x_raw, y_true) in data:\n",
    "    probs = model.forward(x_raw)\n",
    "    pred = 1 if probs[0].data > 0.5 else 0\n",
    "    print(f\"x={x_raw}, y_true={y_true}, prob={probs[0].data:.3f}, pred={pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e1230b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.8312\n",
      "Epoch 20/100, Loss: 0.0123\n",
      "Epoch 40/100, Loss: 0.0046\n",
      "Epoch 60/100, Loss: 0.0027\n",
      "Epoch 80/100, Loss: 0.0019\n",
      "Epoch 100/100, Loss: 0.0015\n",
      "Test Loss: 0.0014\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0014467114773282646"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Models.MLP import MLPNetwork\n",
    "from Trainer.trainer import Trainer\n",
    "data = [\n",
    "    ([2.0, 3.0], [0,1]),\n",
    "    ([1.0, 1.5], [0,1]),\n",
    "    ([2.5, 2.2], [0,1]),\n",
    "    ([3.0, 0.5], [0,1]),\n",
    "    ([4.0, 1.0], [0,1]),\n",
    "    ([3.5, 0.2], [0,1]),\n",
    "]\n",
    "predictors = []\n",
    "labels = []\n",
    "\n",
    "for x,y in data:\n",
    "    predictors.append(x)\n",
    "    labels.append(y)\n",
    "\n",
    "model = MLPNetwork(input_dim=2, n_neurons=[4, 2], label=\"toy\", activation_type=\"tanh\", classification=\"none\")\n",
    "trainer = Trainer(model=model, epochs=100)\n",
    "trainer.fit(predictors, labels)\n",
    "trainer.test(predictors, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9af505",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
