{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c422b3c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MLPNetwork' object has no attribute 'forward'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 52\u001b[39m\n\u001b[32m     48\u001b[39m correct = \u001b[32m0\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m (x_raw, y_true) \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[32m     51\u001b[39m     \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     probs = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m(x_raw)\n\u001b[32m     53\u001b[39m     loss = bce_loss(probs[\u001b[32m0\u001b[39m], y_true)\n\u001b[32m     55\u001b[39m     \u001b[38;5;66;03m# Accumulate loss for reporting\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'MLPNetwork' object has no attribute 'forward'"
     ]
    }
   ],
   "source": [
    "\n",
    "from Models.MLPnetwork import MLPNetwork\n",
    "from Models.Value import Value\n",
    "from Trainer import Trainer\n",
    "data = [\n",
    "    ([2.0, 3.0], 0),\n",
    "    ([1.0, 1.5], 0),\n",
    "    ([2.5, 2.2], 0),\n",
    "    ([3.0, 0.5], 1),\n",
    "    ([4.0, 1.0], 1),\n",
    "    ([3.5, 0.2], 1),\n",
    "]\n",
    "\n",
    "# Binary Cross-Entropy loss for sigmoid outputs\n",
    "def bce_loss(prob, y_true):\n",
    "    \"\"\"\n",
    "    Binary Cross-Entropy Loss for sigmoid outputs.\n",
    "    \n",
    "    prob: Value    # model output after sigmoid (a probability)\n",
    "    y_true: int    # 0 or 1\n",
    "    \"\"\"\n",
    "\n",
    "    # y * log(p)\n",
    "    term1 = prob.log() if y_true == 1 else Value(0.0)\n",
    "\n",
    "    # (1 - y) * log(1 - p)\n",
    "    term2 = (1 - prob).log() if y_true == 0 else Value(0.0)\n",
    "\n",
    "    # BCE = - (term1 + term2)\n",
    "    return -(term1 + term2)\n",
    "    \n",
    "\n",
    "\n",
    "# creating the model with 1 hidden layer and 1 output\n",
    "model = MLPNetwork(\n",
    "    input_dim=2,\n",
    "    n_neurons=[4, 1],          # [hidden_size, output_size]\n",
    "    label=\"toy\",\n",
    "    activation_type=\"tanh\",\n",
    "    classification=\"sigmoid\"\n",
    ")\n",
    "\n",
    "# Training loop (simple SGD)\n",
    "learning_rate = 0.1\n",
    "epochs = 200\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = Value(0.0)\n",
    "    correct = 0\n",
    "\n",
    "    for (x_raw, y_true) in data:\n",
    "        # Forward pass\n",
    "        probs = model.forward(x_raw)\n",
    "        loss = bce_loss(probs[0], y_true)\n",
    "\n",
    "        # Accumulate loss for reporting\n",
    "        total_loss = total_loss + loss\n",
    "\n",
    "        # Accuracy\n",
    "        pred = 1 if probs[0].data > 0.5 else 0\n",
    "        if pred == y_true:\n",
    "            correct += 1\n",
    "\n",
    "        # Backward + update (SGD step)\n",
    "        model.zero_grad()     # reset grads BEFORE backward\n",
    "        loss.backward()\n",
    "        for p in model.parameters():\n",
    "            p.data -= learning_rate * p.grad\n",
    "\n",
    "    # Report average loss + accuracy\n",
    "    if epoch % 20 == 0:\n",
    "        avg_loss = total_loss.data / len(data)\n",
    "        acc = correct / len(data)\n",
    "        print(f\"epoch {epoch:3d} | loss={avg_loss:.4f} | acc={acc:.2f}\")\n",
    "\n",
    "# test\n",
    "print(\"\\nFinal predictions:\")\n",
    "for (x_raw, y_true) in data:\n",
    "    probs = model.forward(x_raw)\n",
    "    pred = 1 if probs[0].data > 0.5 else 0\n",
    "    print(f\"x={x_raw}, y_true={y_true}, prob={probs[0].data:.3f}, pred={pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e1230b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer initialized for regression task using LinearLoss loss.\n",
      "Epoch 1/100, Loss: 0.6469\n",
      "Epoch 20/100, Loss: 0.0320\n",
      "Epoch 40/100, Loss: 0.0149\n",
      "Epoch 60/100, Loss: 0.0107\n",
      "Epoch 80/100, Loss: 0.0081\n",
      "Epoch 100/100, Loss: 0.0063\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.005898927136473401"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Models.MLP import MLPNetwork\n",
    "from Trainer.trainer import Trainer\n",
    "data = [\n",
    "    ([2.0, 3.0], [0,1]),\n",
    "    ([1.0, 1.5], [0,1]),\n",
    "    ([2.5, 2.2], [0,1]),\n",
    "    ([3.0, 0.5], [0,1]),\n",
    "    ([4.0, 1.0], [0,1]),\n",
    "    ([3.5, 0.2], [0,1]),\n",
    "]\n",
    "predictors = []\n",
    "labels = []\n",
    "\n",
    "for x,y in data:\n",
    "    predictors.append(x)\n",
    "    labels.append(y)\n",
    "\n",
    "model = MLPNetwork(input_dim=2, n_neurons=[4, 2], label=\"toy\", activation_type=\"tanh\", classification=\"none\")\n",
    "trainer = Trainer(model=model, epochs=100)\n",
    "trainer.fit(predictors, labels)\n",
    "trainer.test(predictors, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b9af505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def make_toy_data(n_per_class=100):\n",
    "    X_real = []\n",
    "    y_labels = []\n",
    "\n",
    "    for _ in range(n_per_class):\n",
    "        # class 0: around (-1, -1)\n",
    "        x1 = -1 + random.gauss(0, 0.2)\n",
    "        x2 = -1 + random.gauss(0, 0.2)\n",
    "        X_real.append([x1, x2])\n",
    "        y_labels.append(0)\n",
    "\n",
    "    for _ in range(n_per_class):\n",
    "        # class 1: around (1, 1)\n",
    "        x1 = 1 + random.gauss(0, 0.2)\n",
    "        x2 = 1 + random.gauss(0, 0.2)\n",
    "        X_real.append([x1, x2])\n",
    "        y_labels.append(1)\n",
    "\n",
    "    return X_real, y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1eb601e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer initialized for regression task using LinearLoss loss.\n"
     ]
    }
   ],
   "source": [
    "from Models.MLPGenerator import MLPGenerator\n",
    "from Trainer.trainer import Trainer\n",
    "import random\n",
    "\n",
    "def make_toy_data(n_per_class=100):\n",
    "    X_real = []\n",
    "    y_labels = []\n",
    "\n",
    "    for _ in range(n_per_class):\n",
    "        # class 0: around (-1, -1)\n",
    "        x1 = -1 + random.gauss(0, 0.2)\n",
    "        x2 = -1 + random.gauss(0, 0.2)\n",
    "        X_real.append([x1, x2])\n",
    "        y_labels.append(0)\n",
    "\n",
    "    for _ in range(n_per_class):\n",
    "        # class 1: around (1, 1)\n",
    "        x1 = 1 + random.gauss(0, 0.2)\n",
    "        x2 = 1 + random.gauss(0, 0.2)\n",
    "        X_real.append([x1, x2])\n",
    "        y_labels.append(1)\n",
    "\n",
    "    return X_real, y_labels\n",
    "\n",
    "def to_one_hot(label, num_classes):\n",
    "    return [1 if i == label else 0 for i in range(num_classes)]\n",
    "\n",
    "def build_generator_training_data(X_real, y_labels, latent_dim, num_classes):\n",
    "    X_train = []   # inputs to generator\n",
    "    y_train = []   # targets (real x)\n",
    "\n",
    "    for x, y in zip(X_real, y_labels):\n",
    "        # sample random noise z\n",
    "        z = [random.uniform(-1, 1) for _ in range(latent_dim)]\n",
    "        # one-hot encode label\n",
    "        y_vec = to_one_hot(y, num_classes)\n",
    "        # concat [z, y_onehot] as input\n",
    "        inp = z + y_vec\n",
    "\n",
    "        X_train.append(inp)\n",
    "        y_train.append(x)\n",
    "\n",
    "    return X_train, y_train\n",
    "# hyperparameters\n",
    "latent_dim  = 4          # size of noise vector z\n",
    "num_classes = 2          # y in {0, 1}\n",
    "cond_dim    = num_classes\n",
    "output_dim  = 2          # x is 2D\n",
    "hidden_sizes = [16, 16]  # small MLP\n",
    "\n",
    "# create generator model\n",
    "gen_model = MLPGenerator(\n",
    "    latent_dim=latent_dim,\n",
    "    cond_dim=cond_dim,\n",
    "    output_dim=output_dim,\n",
    "    hidden_sizes=hidden_sizes,\n",
    "    activation_type=\"tanh\"\n",
    ")\n",
    "\n",
    "# create trainer (regression, so classification=\"none\" in model)\n",
    "trainer = Trainer(\n",
    "    model=gen_model,\n",
    "    optimizer=None,      # uses default SGD in your __init__\n",
    "    loss_fn=None,        # uses default LinearLoss in your __init__\n",
    "    epochs=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c691b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 0.2782\n",
      "Epoch 20/50, Loss: 0.0442\n",
      "Epoch 40/50, Loss: 0.0426\n"
     ]
    }
   ],
   "source": [
    "# 1. real data\n",
    "X_real, y_labels = make_toy_data(n_per_class=200)\n",
    "\n",
    "# 2. build (input, target) pairs for generator\n",
    "X_train, y_train = build_generator_training_data(\n",
    "    X_real, y_labels,\n",
    "    latent_dim=latent_dim,\n",
    "    num_classes=num_classes\n",
    ")\n",
    "\n",
    "# 3. train\n",
    "trainer.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8d7d60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic samples for class 0:\n",
      "[Value: -1.0559758216501918, Grad: 0, Value: -0.9542930327942515, Grad: 0]\n",
      "[Value: -0.9809952181716437, Grad: 0, Value: -1.0358120493219025, Grad: 0]\n",
      "[Value: -1.0725440286621213, Grad: 0, Value: -0.9512467152491785, Grad: 0]\n",
      "[Value: -1.0064335722720055, Grad: 0, Value: -1.0117034090288402, Grad: 0]\n",
      "[Value: -0.9000556539326645, Grad: 0, Value: -1.049317561478556, Grad: 0]\n",
      "\n",
      "Synthetic samples for class 1:\n",
      "[Value: 0.9608756327356689, Grad: 0, Value: 0.9623279563241465, Grad: 0]\n",
      "[Value: 1.0562431388054598, Grad: 0, Value: 0.9640717531464561, Grad: 0]\n",
      "[Value: 1.014131203869769, Grad: 0, Value: 0.9649806802962615, Grad: 0]\n",
      "[Value: 1.1632670713306237, Grad: 0, Value: 0.8835455789731771, Grad: 0]\n",
      "[Value: 1.0035622775327868, Grad: 0, Value: 0.9617033974953391, Grad: 0]\n"
     ]
    }
   ],
   "source": [
    "def sample_z(latent_dim):\n",
    "    return [random.uniform(-1, 1) for _ in range(latent_dim)]\n",
    "\n",
    "# generate 5 new samples for class 0\n",
    "print(\"Synthetic samples for class 0:\")\n",
    "for _ in range(5):\n",
    "    z = sample_z(latent_dim)\n",
    "    y_vec = to_one_hot(0, num_classes)      # condition on class 0\n",
    "    x_hat = gen_model.generate(z, y_vec)\n",
    "    print(x_hat)\n",
    "\n",
    "# generate 5 new samples for class 1\n",
    "print(\"\\nSynthetic samples for class 1:\")\n",
    "for _ in range(5):\n",
    "    z = sample_z(latent_dim)\n",
    "    y_vec = to_one_hot(1, num_classes)      # condition on class 1\n",
    "    x_hat = gen_model.generate(z, y_vec)\n",
    "    print(x_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "048db89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer initialized for regression task using LinearLoss loss.\n",
      "Epoch 1/20, Loss: 1.9042\n",
      "Epoch 20/20, Loss: 0.1629\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from Utils import data_builder\n",
    " \n",
    "df = pd.read_csv(\"/Users/peter/Library/CloudStorage/OneDrive-Personal/Documents/MDS_UBC/iris.csv\")\n",
    "\n",
    "df[\"Species\"] = df[\"Species\"].astype(\"category\").cat.codes\n",
    "\n",
    "X_train, y_train = data_builder.build_generator_training_data(\n",
    "    df.iloc[:, :-1].values.tolist(),\n",
    "    df[\"Species\"].tolist(),\n",
    "    latent_dim=4\n",
    ")\n",
    "\n",
    "\n",
    "from Models.MLPGenerator import MLPGenerator\n",
    "from Trainer.trainer import Trainer\n",
    "\n",
    "model = MLPGenerator(\n",
    "    latent_dim=4,\n",
    "    cond_dim=1,\n",
    "    output_dim=4,\n",
    "    hidden_sizes=[16, 16],\n",
    "    activation_type=\"tanh\"\n",
    ")\n",
    "\n",
    "train = Trainer(model=model, epochs=20)\n",
    "train.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "383a9de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "seed_vectors = [[random.uniform(-1, 1) for _ in range(4)] for _ in range(len(df[\"Species\"]))]\n",
    "random_labels = df[\"Species\"].tolist()\n",
    "\n",
    "list_of_generated = []\n",
    "for z, y in zip(seed_vectors, random_labels):\n",
    "    list_of_generated.append((model.generate(z, [y]), y))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c6336a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([5.275207124823355,\n",
       "   3.452802953243714,\n",
       "   1.630664621221457,\n",
       "   0.13585715845030505],\n",
       "  0),\n",
       " ([5.083191841224717,\n",
       "   3.295819067174452,\n",
       "   1.7386378178509143,\n",
       "   0.10451614458751872],\n",
       "  0),\n",
       " ([5.1542399749569086,\n",
       "   3.6500859837512625,\n",
       "   1.5229015302901336,\n",
       "   0.11106235812560017],\n",
       "  0),\n",
       " ([5.071925157871115,\n",
       "   3.2523337531786343,\n",
       "   1.8186026675909797,\n",
       "   0.16269299332196469],\n",
       "  0),\n",
       " ([5.251641028885373,\n",
       "   3.2757570924101276,\n",
       "   1.5756057513845516,\n",
       "   0.2598734309839952],\n",
       "  0),\n",
       " ([4.416155139129472,\n",
       "   3.3989735226549933,\n",
       "   1.3726169104132195,\n",
       "   0.34047216980861345],\n",
       "  0),\n",
       " ([4.772154332688933,\n",
       "   3.4773903779374105,\n",
       "   1.7077089357432913,\n",
       "   0.6075754307003657],\n",
       "  0),\n",
       " ([4.778021455984011,\n",
       "   3.4489801887522398,\n",
       "   1.5159990262258176,\n",
       "   -0.0851797571335774],\n",
       "  0),\n",
       " ([5.195741178790682,\n",
       "   3.672338665914862,\n",
       "   1.2854420838708858,\n",
       "   0.019967059253662878],\n",
       "  0),\n",
       " ([5.093050710590327,\n",
       "   3.5558448881911877,\n",
       "   1.4104926898234642,\n",
       "   0.02842209079277519],\n",
       "  0),\n",
       " ([4.869039936071331,\n",
       "   3.416915613408619,\n",
       "   1.4440019293332096,\n",
       "   0.2837154982974916],\n",
       "  0),\n",
       " ([4.9276509778226005,\n",
       "   3.330214365962385,\n",
       "   1.6787714480058424,\n",
       "   0.30884645887610573],\n",
       "  0),\n",
       " ([5.115887974824958,\n",
       "   3.4237197731062055,\n",
       "   1.5169974948123537,\n",
       "   0.22881819865717867],\n",
       "  0),\n",
       " ([5.043340221327542,\n",
       "   3.5560425097966593,\n",
       "   1.4076274808676923,\n",
       "   0.052618542727042306],\n",
       "  0),\n",
       " ([4.974495479719501,\n",
       "   3.5726509337244767,\n",
       "   1.3761818738755207,\n",
       "   0.16195680970228732],\n",
       "  0),\n",
       " ([4.678313900380746,\n",
       "   3.330512890533574,\n",
       "   1.4700553807321388,\n",
       "   0.3264359175926548],\n",
       "  0),\n",
       " ([4.990633671544642,\n",
       "   3.5222388896665455,\n",
       "   1.4267567723133556,\n",
       "   0.3228735661390794],\n",
       "  0),\n",
       " ([5.070550596189307,\n",
       "   3.152759468799529,\n",
       "   1.6028818406063516,\n",
       "   0.44999569261872696],\n",
       "  0),\n",
       " ([5.259932284126087,\n",
       "   3.625333020984701,\n",
       "   1.5239153358739201,\n",
       "   0.09281540616748918],\n",
       "  0),\n",
       " ([5.263647852774158,\n",
       "   3.6549754710881754,\n",
       "   1.467395532847841,\n",
       "   0.06727842971427156],\n",
       "  0),\n",
       " ([5.040307325075884,\n",
       "   3.2932657064899367,\n",
       "   1.6328477787625617,\n",
       "   0.08292899413350965],\n",
       "  0),\n",
       " ([4.962500422829235,\n",
       "   3.4975250420276653,\n",
       "   1.5363124227054747,\n",
       "   0.27189066964836883],\n",
       "  0),\n",
       " ([5.277559444860067,\n",
       "   3.512986614669838,\n",
       "   1.8485387117506271,\n",
       "   0.39720335783852284],\n",
       "  0),\n",
       " ([5.112548871983646,\n",
       "   3.489055932985868,\n",
       "   1.541011684245353,\n",
       "   0.19021314257896155],\n",
       "  0),\n",
       " ([4.933747496992526,\n",
       "   3.683515825981186,\n",
       "   1.738988316388161,\n",
       "   0.15310561484488477],\n",
       "  0),\n",
       " ([5.23352825471454,\n",
       "   3.4241386226270625,\n",
       "   1.6008784761921993,\n",
       "   0.25956437737302385],\n",
       "  0),\n",
       " ([4.839570091285025,\n",
       "   3.388016354680777,\n",
       "   1.5980884369225619,\n",
       "   0.12879917073599095],\n",
       "  0),\n",
       " ([4.820056294744852,\n",
       "   3.5050730270531067,\n",
       "   1.333386278090469,\n",
       "   0.20874617387591982],\n",
       "  0),\n",
       " ([5.156882529395475,\n",
       "   3.405099038333686,\n",
       "   1.5069050106500872,\n",
       "   0.20482968308639382],\n",
       "  0),\n",
       " ([5.090619205898711,\n",
       "   3.256069215222986,\n",
       "   1.699793092422908,\n",
       "   0.17410183124155426],\n",
       "  0),\n",
       " ([5.128471450431921,\n",
       "   3.5925308416105817,\n",
       "   1.471238937729918,\n",
       "   -0.005841376768292661],\n",
       "  0),\n",
       " ([4.9376867750111035,\n",
       "   3.5200500258954017,\n",
       "   1.5781811656484965,\n",
       "   0.05120869531033606],\n",
       "  0),\n",
       " ([4.47440245770428,\n",
       "   3.3223759750558894,\n",
       "   1.6774293401760292,\n",
       "   0.2969646645997081],\n",
       "  0),\n",
       " ([4.753128938979085,\n",
       "   3.4846378806791436,\n",
       "   1.5537136368986704,\n",
       "   0.5397056586343129],\n",
       "  0),\n",
       " ([5.314126065590489,\n",
       "   3.4271821679377106,\n",
       "   1.4853682153589272,\n",
       "   0.1893932719925761],\n",
       "  0),\n",
       " ([4.9770667014960805,\n",
       "   3.9530920353847043,\n",
       "   1.5618069186657224,\n",
       "   0.15202479221759624],\n",
       "  0),\n",
       " ([4.880192325109766,\n",
       "   3.1936268156991834,\n",
       "   1.7923289297678875,\n",
       "   0.41127444679079694],\n",
       "  0),\n",
       " ([4.50734658344081, 3.399456558033272, 1.518405616560155, 0.5797448731798898],\n",
       "  0),\n",
       " ([4.943503283388932,\n",
       "   3.338662502645735,\n",
       "   1.6004957690921073,\n",
       "   0.42348986394446664],\n",
       "  0),\n",
       " ([5.197832094313144,\n",
       "   3.5840166929282873,\n",
       "   1.5842164394338416,\n",
       "   0.12176464537536796],\n",
       "  0),\n",
       " ([4.898458738011637,\n",
       "   3.571839213321607,\n",
       "   1.5256748720629743,\n",
       "   0.2754596086435916],\n",
       "  0),\n",
       " ([4.358574290492983,\n",
       "   3.023500527558893,\n",
       "   1.6773438250419455,\n",
       "   0.900759303413716],\n",
       "  0),\n",
       " ([4.8903798262703315,\n",
       "   3.5636485532029947,\n",
       "   1.5484304392626327,\n",
       "   0.36275396619405326],\n",
       "  0),\n",
       " ([5.132967766442112,\n",
       "   3.5779126912670507,\n",
       "   1.3312495569898612,\n",
       "   0.028383407145367245],\n",
       "  0),\n",
       " ([5.0152793088588,\n",
       "   3.634823391302656,\n",
       "   1.3825408099034715,\n",
       "   0.11060645095764732],\n",
       "  0),\n",
       " ([5.27835421651875,\n",
       "   3.442147031497005,\n",
       "   1.5839219597116687,\n",
       "   0.09581835192495963],\n",
       "  0),\n",
       " ([5.033689267019316,\n",
       "   3.3779184942817664,\n",
       "   1.787518240261973,\n",
       "   0.5669395530538702],\n",
       "  0),\n",
       " ([5.081924275175406,\n",
       "   3.2533047010971927,\n",
       "   1.6352039033932118,\n",
       "   0.5096945647457725],\n",
       "  0),\n",
       " ([5.000459039779184,\n",
       "   3.55631762701067,\n",
       "   1.3790213426900213,\n",
       "   0.12358360772458604],\n",
       "  0),\n",
       " ([4.783812154093265,\n",
       "   3.233782900762778,\n",
       "   1.4890828373829925,\n",
       "   0.42892156052959873],\n",
       "  0),\n",
       " ([5.803722624053138, 2.6771765952794224, 4.46822106744469, 1.880809667106745],\n",
       "  1),\n",
       " ([6.163144361185921,\n",
       "   2.8377475094780316,\n",
       "   4.318791723662015,\n",
       "   1.4357150784015775],\n",
       "  1),\n",
       " ([6.069808290243333, 2.733882557443589, 4.336192186030273, 1.49628671658496],\n",
       "  1),\n",
       " ([6.24860859280855,\n",
       "   2.983080340520297,\n",
       "   4.5208470963441325,\n",
       "   1.4276919397812777],\n",
       "  1),\n",
       " ([6.350122888448162,\n",
       "   2.929430796562255,\n",
       "   4.583860446318233,\n",
       "   1.3684798151106876],\n",
       "  1),\n",
       " ([6.384610689711824,\n",
       "   2.8171767392896796,\n",
       "   4.2803781827673815,\n",
       "   1.4616224019124902],\n",
       "  1),\n",
       " ([5.750380669660909,\n",
       "   2.6694356924309597,\n",
       "   3.7679327217680965,\n",
       "   1.214920005887936],\n",
       "  1),\n",
       " ([6.103812608680967,\n",
       "   2.9551033176099226,\n",
       "   4.598146594295781,\n",
       "   1.4407927119801016],\n",
       "  1),\n",
       " ([6.244752875190923,\n",
       "   2.947630075674492,\n",
       "   4.674615475402711,\n",
       "   1.4599681916942049],\n",
       "  1),\n",
       " ([5.880222946086837,\n",
       "   2.781089883324179,\n",
       "   4.008991274118437,\n",
       "   1.2514038093898294],\n",
       "  1),\n",
       " ([6.09871267038097, 2.722688911298906, 4.396277452878029, 1.5632803834258828],\n",
       "  1),\n",
       " ([6.304856671972028,\n",
       "   3.011680844896134,\n",
       "   4.124713935384603,\n",
       "   1.4865072686050698],\n",
       "  1),\n",
       " ([6.3377419344434935,\n",
       "   2.8377930212363767,\n",
       "   4.286580301987614,\n",
       "   1.5467259404249845],\n",
       "  1),\n",
       " ([6.248846877733697,\n",
       "   3.257473060956333,\n",
       "   4.615136417184719,\n",
       "   1.5148215045381164],\n",
       "  1),\n",
       " ([6.00039486970879, 2.8692250701986253, 4.451950833743362, 1.436281523392025],\n",
       "  1),\n",
       " ([6.092568848841316,\n",
       "   2.762529373961649,\n",
       "   4.182005014368727,\n",
       "   1.5655084922827802],\n",
       "  1),\n",
       " ([5.89981579137091, 2.8158233899309844, 4.17933266672117, 1.332542715416939],\n",
       "  1),\n",
       " ([6.222876753701059,\n",
       "   3.0970568276046824,\n",
       "   4.555482788791426,\n",
       "   1.4614359840087325],\n",
       "  1),\n",
       " ([6.13333686778382,\n",
       "   2.8685042119670716,\n",
       "   4.467890246138061,\n",
       "   1.4277930470851306],\n",
       "  1),\n",
       " ([5.73349876062282,\n",
       "   2.676105109318942,\n",
       "   3.7687430336515653,\n",
       "   1.2179614783715138],\n",
       "  1),\n",
       " ([6.2494131626683815,\n",
       "   2.953411928877382,\n",
       "   4.5804909337367095,\n",
       "   1.4458583470968434],\n",
       "  1),\n",
       " ([5.65412789567913,\n",
       "   2.8033166823025404,\n",
       "   3.7401863084426603,\n",
       "   1.2319309303700225],\n",
       "  1),\n",
       " ([5.954541305989433,\n",
       "   2.8844173666040835,\n",
       "   4.1421307826768405,\n",
       "   1.4160204642033682],\n",
       "  1),\n",
       " ([5.937194626206201, 2.904867891792878, 4.224655555076654, 1.34212714113541],\n",
       "  1),\n",
       " ([6.00199797710746,\n",
       "   2.939544085122366,\n",
       "   4.3977581057743125,\n",
       "   1.5790469897399313],\n",
       "  1),\n",
       " ([6.062030148243729, 2.92279712342616, 4.479016371938598, 1.4172931046524226],\n",
       "  1),\n",
       " ([6.038657606001972,\n",
       "   2.7261803687703137,\n",
       "   4.422620861414845,\n",
       "   1.5488431320845746],\n",
       "  1),\n",
       " ([6.225659707395468,\n",
       "   2.8892043804907526,\n",
       "   4.338787383922157,\n",
       "   1.5721277078844162],\n",
       "  1),\n",
       " ([6.257825269834337,\n",
       "   2.987524815408222,\n",
       "   4.575165800166707,\n",
       "   1.4319837103830682],\n",
       "  1),\n",
       " ([6.103054956405415,\n",
       "   3.2837127934287786,\n",
       "   4.678572167839316,\n",
       "   1.6155035144738623],\n",
       "  1),\n",
       " ([6.300695205393884,\n",
       "   2.967189934955268,\n",
       "   4.570957438589072,\n",
       "   1.3637377399904511],\n",
       "  1),\n",
       " ([6.141211082737403, 3.117166545803718, 4.406922041393054, 1.519203839195487],\n",
       "  1),\n",
       " ([5.977065723777236, 2.849400537355356, 4.228968623477415, 1.435933547080927],\n",
       "  1),\n",
       " ([6.10268404342004, 2.932319932144836, 4.589330030898965, 1.4471988202953678],\n",
       "  1),\n",
       " ([6.114982398767126,\n",
       "   2.937243179574826,\n",
       "   4.521954281945369,\n",
       "   1.5495108404473337],\n",
       "  1),\n",
       " ([5.986860372843076,\n",
       "   2.8937319891044213,\n",
       "   4.285574916893066,\n",
       "   1.4400212436768929],\n",
       "  1),\n",
       " ([6.387661022666752,\n",
       "   2.991329454645263,\n",
       "   4.016443806748576,\n",
       "   1.3847146441665568],\n",
       "  1),\n",
       " ([6.260864992295856,\n",
       "   2.787634662183182,\n",
       "   4.473671094406246,\n",
       "   1.4728797390603647],\n",
       "  1),\n",
       " ([6.071145208337763,\n",
       "   2.9535685816071893,\n",
       "   4.515534022828206,\n",
       "   1.5920621790932732],\n",
       "  1),\n",
       " ([5.8285015261097985,\n",
       "   2.7565631589710775,\n",
       "   4.003336004041684,\n",
       "   1.2970021947752501],\n",
       "  1),\n",
       " ([6.214460172579555,\n",
       "   3.0228590852123163,\n",
       "   4.555135865855522,\n",
       "   1.4476769260908213],\n",
       "  1),\n",
       " ([5.911186181073533, 2.972875771659618, 4.46433127943911, 1.6663050487201727],\n",
       "  1),\n",
       " ([6.001683776700386,\n",
       "   2.9229183009207427,\n",
       "   4.420032791287727,\n",
       "   1.3955033155334138],\n",
       "  1),\n",
       " ([6.325045615562448,\n",
       "   2.989271409928422,\n",
       "   4.574689412346284,\n",
       "   1.3612301459066707],\n",
       "  1),\n",
       " ([6.14806509296252, 2.838546176200646, 4.367958800750308, 1.430942357466285],\n",
       "  1),\n",
       " ([6.463858240023533,\n",
       "   2.657290999717798,\n",
       "   4.3906831654817475,\n",
       "   1.5085338420394516],\n",
       "  1),\n",
       " ([6.427375413143329,\n",
       "   2.8834038929570434,\n",
       "   3.937691031195758,\n",
       "   1.2888081240977387],\n",
       "  1),\n",
       " ([6.046722946386984,\n",
       "   2.8937856264672708,\n",
       "   4.503385899029635,\n",
       "   1.451743803981197],\n",
       "  1),\n",
       " ([6.2306198250344735,\n",
       "   2.929254322303934,\n",
       "   4.172678259515884,\n",
       "   1.3112024817878287],\n",
       "  1),\n",
       " ([6.321329966742138,\n",
       "   3.150881950956349,\n",
       "   4.322897020288702,\n",
       "   1.3871182582449748],\n",
       "  1),\n",
       " ([6.791802330417472, 2.852016793649226, 5.856775605143832, 2.038382348565918],\n",
       "  2),\n",
       " ([6.756255387228874, 2.921926523834718, 6.013951198605488, 2.00279059847992],\n",
       "  2),\n",
       " ([6.761562473187494,\n",
       "   2.9781144660086087,\n",
       "   5.901138805601397,\n",
       "   1.927500076697592],\n",
       "  2),\n",
       " ([6.613287240963243, 2.863872417813141, 5.752531082092947, 1.908504287117978],\n",
       "  2),\n",
       " ([6.70452462900355, 2.954230001860094, 5.836348379773916, 2.001475863935001],\n",
       "  2),\n",
       " ([6.664933872848251,\n",
       "   2.907946244580394,\n",
       "   5.812232850842596,\n",
       "   1.9052810174324388],\n",
       "  2),\n",
       " ([6.410745655681586,\n",
       "   2.9294761903942526,\n",
       "   5.454608775630404,\n",
       "   1.793888503161169],\n",
       "  2),\n",
       " ([6.537227826240073,\n",
       "   2.690754330024114,\n",
       "   5.594669543309298,\n",
       "   1.9614897063700079],\n",
       "  2),\n",
       " ([6.748911331985916,\n",
       "   2.924664975584951,\n",
       "   5.8618379031297065,\n",
       "   1.9627994131699946],\n",
       "  2),\n",
       " ([6.639214358134508,\n",
       "   3.129675636153932,\n",
       "   5.800423418796829,\n",
       "   1.9572487881492924],\n",
       "  2),\n",
       " ([6.718886044643869,\n",
       "   3.0084050962029893,\n",
       "   5.8313540875735335,\n",
       "   1.9308002681812322],\n",
       "  2),\n",
       " ([6.732018679443548,\n",
       "   2.9986131141277683,\n",
       "   5.879712584843483,\n",
       "   1.9626702842250454],\n",
       "  2),\n",
       " ([6.556263151960939,\n",
       "   2.7202259510549793,\n",
       "   5.622032619159237,\n",
       "   1.9561523512338714],\n",
       "  2),\n",
       " ([6.636546876327654, 2.985491730443857, 5.85955417220557, 1.9603660362912925],\n",
       "  2),\n",
       " ([6.70910501670254, 2.977123279719913, 5.721661590172507, 2.023544150915936],\n",
       "  2),\n",
       " ([6.5078292778482245,\n",
       "   2.764703821002227,\n",
       "   5.581885961302705,\n",
       "   1.888570306624371],\n",
       "  2),\n",
       " ([6.667317253371302, 2.9270079532608126, 5.79483585445415, 2.024770607024417],\n",
       "  2),\n",
       " ([6.604120308083354,\n",
       "   2.942442336310608,\n",
       "   5.792636442912677,\n",
       "   1.9040226059062684],\n",
       "  2),\n",
       " ([6.708255539698625,\n",
       "   2.9634809003590306,\n",
       "   5.822583845187648,\n",
       "   1.9452085857480106],\n",
       "  2),\n",
       " ([6.735700218048489,\n",
       "   2.9924184667494225,\n",
       "   5.892573325500409,\n",
       "   1.9209976339003094],\n",
       "  2),\n",
       " ([6.7898944980634965,\n",
       "   2.9015005542821823,\n",
       "   5.865803285948158,\n",
       "   2.0103862449544714],\n",
       "  2),\n",
       " ([6.7182967778976606,\n",
       "   2.896935201817292,\n",
       "   5.839462434124029,\n",
       "   1.929799042751837],\n",
       "  2),\n",
       " ([6.324278684058554,\n",
       "   2.912931543183492,\n",
       "   5.6173805621790525,\n",
       "   2.141896605563385],\n",
       "  2),\n",
       " ([6.72357538330484,\n",
       "   2.9843462567417953,\n",
       "   5.918661385267736,\n",
       "   1.9691872534280235],\n",
       "  2),\n",
       " ([6.574539938624843,\n",
       "   2.9503050491128895,\n",
       "   5.739974685023041,\n",
       "   1.9304766670363764],\n",
       "  2),\n",
       " ([6.709123359474097,\n",
       "   2.9666887074769024,\n",
       "   5.933203996729934,\n",
       "   1.9374020699391934],\n",
       "  2),\n",
       " ([6.687099766630592,\n",
       "   2.9961235384216045,\n",
       "   5.850367098672401,\n",
       "   1.9072186209737445],\n",
       "  2),\n",
       " ([6.668005862079128,\n",
       "   3.0331518490507405,\n",
       "   5.825161893445905,\n",
       "   1.9390870276290564],\n",
       "  2),\n",
       " ([6.799075034204061,\n",
       "   2.9260369257030554,\n",
       "   5.970367770066207,\n",
       "   1.968665190163736],\n",
       "  2),\n",
       " ([6.742454124874322,\n",
       "   2.9312343490969464,\n",
       "   5.956902807963518,\n",
       "   1.9690675553916366],\n",
       "  2),\n",
       " ([6.504428196294807,\n",
       "   2.9224213649369837,\n",
       "   5.608653785328469,\n",
       "   1.9253575171678146],\n",
       "  2),\n",
       " ([6.642491500228876,\n",
       "   2.949592423390276,\n",
       "   5.964759604445997,\n",
       "   2.0737881807996947],\n",
       "  2),\n",
       " ([6.623321718948414,\n",
       "   2.89609633593146,\n",
       "   5.8831529964201374,\n",
       "   2.0407406802753965],\n",
       "  2),\n",
       " ([6.557145480462554,\n",
       "   3.020644241868427,\n",
       "   5.7788181033575725,\n",
       "   1.9928107562813062],\n",
       "  2),\n",
       " ([6.670081754724045, 2.886572884777073, 5.716702056561767, 2.080992735059214],\n",
       "  2),\n",
       " ([6.751525910406267,\n",
       "   2.8640739070916417,\n",
       "   5.786811511136759,\n",
       "   2.0163324092745447],\n",
       "  2),\n",
       " ([6.649345124435622,\n",
       "   2.883221534798283,\n",
       "   5.843595458042281,\n",
       "   2.0626448974258067],\n",
       "  2),\n",
       " ([6.680161195271516,\n",
       "   2.948122489188755,\n",
       "   5.849603076598701,\n",
       "   1.9113356929675003],\n",
       "  2),\n",
       " ([6.710950004835697,\n",
       "   3.0050813103842717,\n",
       "   5.8327882971858545,\n",
       "   1.9324004811143902],\n",
       "  2),\n",
       " ([6.574968150135839,\n",
       "   2.876075638193263,\n",
       "   5.860012756029259,\n",
       "   1.9887236092563965],\n",
       "  2),\n",
       " ([6.673277583846403, 2.9264146146564793, 5.905401901287146, 2.05818441871406],\n",
       "  2),\n",
       " ([6.644726037328857,\n",
       "   2.9094143373655297,\n",
       "   5.784771616337135,\n",
       "   1.8819355073920727],\n",
       "  2),\n",
       " ([6.647980507056424,\n",
       "   2.969977084058442,\n",
       "   5.8316032469392365,\n",
       "   1.9243105328873567],\n",
       "  2),\n",
       " ([6.70178775847514,\n",
       "   3.0147291344099134,\n",
       "   5.810232102533017,\n",
       "   1.9371127082456006],\n",
       "  2),\n",
       " ([6.4606066450171005,\n",
       "   2.901107252478926,\n",
       "   5.51441027686991,\n",
       "   1.8252220896313252],\n",
       "  2),\n",
       " ([6.588007283484259,\n",
       "   2.777749143012181,\n",
       "   5.671889562798924,\n",
       "   1.9580934717328162],\n",
       "  2),\n",
       " ([6.690624393337969,\n",
       "   2.974032625639247,\n",
       "   5.863860608367914,\n",
       "   1.9100102874680993],\n",
       "  2),\n",
       " ([6.731736035204996,\n",
       "   2.9654118713188757,\n",
       "   5.787462464447385,\n",
       "   1.9964560995377052],\n",
       "  2),\n",
       " ([6.797328664103662,\n",
       "   2.7987664889721464,\n",
       "   5.824112950945746,\n",
       "   2.064883541419689],\n",
       "  2),\n",
       " ([6.728076896243054,\n",
       "   2.9163450572477836,\n",
       "   5.935092953969416,\n",
       "   1.954269374690605],\n",
       "  2)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb6c4ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Sepal.Length  Sepal.Width  Petal.Length  Petal.Width  Species\n",
      "0      5.275207     3.452803      1.630665     0.135857        0\n",
      "1      5.083192     3.295819      1.738638     0.104516        0\n",
      "2      5.154240     3.650086      1.522902     0.111062        0\n",
      "3      5.071925     3.252334      1.818603     0.162693        0\n",
      "4      5.251641     3.275757      1.575606     0.259873        0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "feature_cols = df.columns.tolist()\n",
    "\n",
    "generated_df = pd.DataFrame(\n",
    "    [x + [label] for x, label in list_of_generated],\n",
    "    columns=feature_cols\n",
    ")\n",
    "\n",
    "print(generated_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b031d5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.902901325996727\n",
      "3.7580000000000005\n",
      "1.2184834269048592\n",
      "1.1993333333333336\n"
     ]
    }
   ],
   "source": [
    "generated_df.head()\n",
    "\n",
    "print(generated_df[\"Petal.Length\"].mean())\n",
    "print(df[\"Petal.Length\"].mean())\n",
    "print(generated_df[\"Petal.Width\"].mean())\n",
    "print(df[\"Petal.Width\"].mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd9924b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer initialized for classification task using str loss.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m predictors = generated_df.iloc[:, :-\u001b[32m1\u001b[39m].values.tolist()\n\u001b[32m      5\u001b[39m labels = generated_df[\u001b[33m\"\u001b[39m\u001b[33mSpecies\u001b[39m\u001b[33m\"\u001b[39m].astype(\u001b[38;5;28mint\u001b[39m).tolist()\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-Personal/Documents/MDS_UBC/DATA_533/Project/datamint/Trainer/trainer.py:74\u001b[39m, in \u001b[36mTrainer.fit\u001b[39m\u001b[34m(self, X, y, batch_size)\u001b[39m\n\u001b[32m     70\u001b[39m target = y[i]\n\u001b[32m     72\u001b[39m outputs = \u001b[38;5;28mself\u001b[39m.model.predict(inputs) \n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m batch_losses.append(loss)\n\u001b[32m     76\u001b[39m epoch_loss += loss.data\n",
      "\u001b[31mTypeError\u001b[39m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "from Models.MLPGenerator import MLPNetwork\n",
    "model_prediction = MLPNetwork(4, [16,16,3], \"iris_pred\", \"tanh\", classification=\"softmax\")\n",
    "trainer = Trainer(model=model_prediction, epochs=50, loss_fn=\"cross_entropy\")\n",
    "predictors = generated_df.iloc[:, :-1].values.tolist()\n",
    "labels = generated_df[\"Species\"].astype(int).tolist()\n",
    "loss_fn = \n",
    "trainer.fit(predictors, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
