{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b982d868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from midi2audio import FluidSynth\n",
    "from IPython.display import Audio\n",
    "from mido import MidiFile, MidiTrack\n",
    "\n",
    "from midi2audio import FluidSynth\n",
    "from IPython.display import Audio\n",
    "\n",
    "\n",
    "def play_midi(midi_filename):\n",
    "    FluidSynth(\"soundfont.sf2\").midi_to_audio(midi_filename, 'test.wav')\n",
    "    return Audio(filename=\"test.wav\") \n",
    "\n",
    "# Update your play_midi function\n",
    "def play_midi(midi_filename):\n",
    "    FluidSynth(\"soundfont.sf2\").midi_to_audio(midi_filename, 'test.wav')\n",
    "    return Audio(\"test.wav\")\n",
    "def get_midi_file_notes(filename):\n",
    "    \"\"\"Returns the sequence of notes played in the midi file\n",
    "    There are 128 possible notes on a MIDI device, and they are numbered 0 to 127.\n",
    "    The middle C is note number 60. Larger numbers indiciate higher pitch notes,\n",
    "    and lower numbers indicate lower pitch notes.\n",
    "    \"\"\"\n",
    "    notes = []\n",
    "    for msg in  MidiFile(filename):\n",
    "        if msg.type == 'note_on':\n",
    "            notes.append(msg.note)\n",
    "    return notes\n",
    "\n",
    "def gen_input_output(notes, context_length=20):\n",
    "    \"\"\"\n",
    "    Generate a list of training data points, each of the form (x, t),\n",
    "    where \"x\" is a list of length `context_length` consisting of the\n",
    "    previous notes, and \"t\" is the corresponding next note.\n",
    "\n",
    "    Parameters:\n",
    "        `notes` - a sequence of notes in a piece, generated\n",
    "                  from calling `get_midi_file_notes`\n",
    "        `context_length` - length of each context\n",
    "\n",
    "    Returns: a list of training pairs (x, t), with len(x) == context_length\n",
    "    \"\"\"\n",
    "    D = []\n",
    "    for i in range(len(notes) - context_length):\n",
    "        seq = notes[i:i+context_length]\n",
    "        next_note = notes[i+context_length]\n",
    "        D.append((seq, next_note),)\n",
    "\n",
    "    D.append((notes[-context_length:], 0),)\n",
    "    # Since the note 0 never appears in any of our pieces,\n",
    "    # we use note 0 to denote END OF SONG.\n",
    "    return D\n",
    "\n",
    "def make_onehot(indicies, total=128):\n",
    "    \"\"\"\n",
    "    Convert indicies into one-hot vectors by\n",
    "    first creating an identity matrix of shape [total, total],\n",
    "    then indexing the appropriate columns of that identity matrix.\n",
    "\n",
    "    Parameters:\n",
    "        `indices` - a numpy array of some shape where\n",
    "                    the value in these arrays should correspond to category\n",
    "                    indices (e.g. note values between 0-127)\n",
    "        `total` - the total number of categories (e.g. total number of notes)\n",
    "\n",
    "    Returns: a numpy array of one-hot vectors\n",
    "        If the `indices` array is shaped (N,)\n",
    "           then the returned array will be shaped (N, total)\n",
    "        If the `indices` array is shaped (N, D)\n",
    "           then the returned array will be shaped (N, D, total)\n",
    "        ... and so on.\n",
    "    \"\"\"\n",
    "    I = np.eye(total)\n",
    "    return I[indicies]\n",
    "\n",
    "def generate_midi(notes, outfile):\n",
    "    from mido import MidiFile, MidiTrack, Message\n",
    "\n",
    "    new_mid = MidiFile()\n",
    "    new_track = MidiTrack()\n",
    "    new_mid.tracks.append(new_track)\n",
    "\n",
    "    for note in notes:\n",
    "        new_track.append(Message('note_on', note=note, velocity=64, time=128))\n",
    "    new_mid.save(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0cf1d5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[76, 74, 71, 69, 71, 72, 71, 67, 69, 76, 74, 71, 69, 71, 72, 71, 65, 67, 76, 74, 71, 69, 71, 72, 71, 67, 69, 76, 74, 71, 69, 71, 72, 71, 65, 67, 76, 79, 76, 77, 74, 72, 69, 65, 76, 79, 76, 77, 74, 72, 69, 67, 76, 79, 76, 77, 74, 72, 69, 65, 76, 79, 76, 77, 74, 72, 69, 67]\n"
     ]
    }
   ],
   "source": [
    "print(get_midi_file_notes('/Users/peter/Downloads/nottingham-dataset-master/MIDI/melody/ashover1.mid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1daa7c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n",
      "68\n"
     ]
    }
   ],
   "source": [
    "sample_song = get_midi_file_notes('/Users/peter/Downloads/nottingham-dataset-master/MIDI/melody/ashover1.mid')\n",
    "D_sample_song = gen_input_output(sample_song)\n",
    "\n",
    "print(len(sample_song))\n",
    "print(len(D_sample_song) + 20 - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "822dd502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer initialized for classification task using CrossEntropyLoss loss.\n"
     ]
    }
   ],
   "source": [
    "from Models.MLPMusicGen import MLPMusicGen\n",
    "from Trainer import Trainer\n",
    "from Trainer.losses import *\n",
    "\n",
    "model = MLPMusicGen(20, [64,64], activation_type=\"tanh\")\n",
    "\n",
    "loss_fun = CrossEntropyLoss()\n",
    "\n",
    "trainer = Trainer(model, optimizer= None, loss_fn=loss_fun)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "770e9890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 30 notes: [76, 74, 71, 69, 71, 72, 71, 67, 69, 76, 74, 71, 69, 71, 72, 71, 65, 67, 76, 74, 39, 118, 35, 77, 25, 37, 2, 67, 120, 79]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error: '-F' is an illegal option at this place, only -b option is allowed here.\n",
      "fluidsynth: error: fluid_is_soundfont(): fopen() failed: 'File does not exist.'\n",
      "Parameter 'test.wav' not a SoundFont or MIDI file or error occurred identifying it.\n",
      "error: '-r' is an illegal option at this place, only -b option is allowed here.\n",
      "fluidsynth: error: fluid_is_soundfont(): fopen() failed: 'File does not exist.'\n",
      "Parameter '44100' not a SoundFont or MIDI file or error occurred identifying it.\n",
      "fluidsynth: warning: End of the MIDI file reached, but not all notes have received a note off event! OFFing them now! Run with --verbose to spot pending voices.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FluidSynth runtime version 2.5.1\n",
      "Copyright (C) 2000-2025 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of Creative Technology Ltd.\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "rate must be specified when data is a numpy array or list of audio samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m generated = generate_midi(notes, \u001b[33m'\u001b[39m\u001b[33muntrained.mid\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGenerated \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(notes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m notes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnotes\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mplay_midi\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43muntrained.mid\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mplay_midi\u001b[39m\u001b[34m(midi_filename)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mplay_midi\u001b[39m(midi_filename):\n\u001b[32m     16\u001b[39m     FluidSynth(\u001b[33m\"\u001b[39m\u001b[33msoundfont.sf2\u001b[39m\u001b[33m\"\u001b[39m).midi_to_audio(midi_filename, \u001b[33m'\u001b[39m\u001b[33mtest.wav\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mAudio\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtest.wav\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/IPython/lib/display.py:129\u001b[39m, in \u001b[36mAudio.__init__\u001b[39m\u001b[34m(self, data, filename, url, embed, rate, autoplay, normalize, element_id)\u001b[39m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.data, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[32m    128\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m rate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mrate must be specified when data is a numpy array or list of audio samples.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    130\u001b[39m     \u001b[38;5;28mself\u001b[39m.data = Audio._make_wav(data, rate, normalize)\n",
      "\u001b[31mValueError\u001b[39m: rate must be specified when data is a numpy array or list of audio samples."
     ]
    }
   ],
   "source": [
    "seed = sample_song[:20]\n",
    "notes = model.generate_piece(seed = seed, max_len = 30)\n",
    "\n",
    "generated = generate_midi(notes, 'untrained.mid')\n",
    "print(f\"Generated {len(notes)} notes: {notes}\") \n",
    "\n",
    "play_midi('untrained.mid')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
